{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"50px\" align=\"left\" style=\"margin-right:20px\" src=\"http://data.cluster-lab.com/public-newprolab-com/npl_logo.png\"> <b>New Professions Lab</b> <br /> Специалист по большим данным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Спрогнозировать пол и возрастную категорию интернет-пользователей по логу посещения сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"110px\" align=\"left\" src=\"http://data.cluster-lab.com/public-newprolab-com/project01_img0.png?img\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из задач DMP-системы состоит в том, чтобы по разрозненным даннным, таким, как посещения неким пользователем сайтов, классифицировать его и присвоить ему определённую категорию: пол, возраст, интересы и так далее. В дальнейшем составляется портрет, или профиль, пользователя, на основе которого ему более таргетированно показывается реклама в интернете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя доступный набор данных о посещении страниц у одной части пользователей, сделать прогноз относительно **пола и возрастной категории** другой части пользователей. Угадывание (hit) - правильное предсказание и пола, и возрастной категории одновременно.\n",
    "\n",
    "Мы не ограничиваем вас в выборе инструментов и методов работы с данными. Используйте любые эвристики, внешние источники, парсинг контента страниц — всё, что поможет вам выполнить задачу. Единственное ограничение — никаких ручных действий. Руками проставлять классы нельзя.\n",
    "\n",
    "Поскольку это ваш проект, который мы наверняка захотите показать другим, уделите его оформлению достаточно времени. Мы рекомендуем сделать весь проект в этом ноутбуке. Снизу, под заданием, вы сможете описать ваше решение.\n",
    "\n",
    "⏰ **Дедлайн: 16 мая 2019, 23:59**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Это - не обычная лабораторка\n",
    "\n",
    "Это - соревнование! В нем есть доска лидеров, которую можно увидеть после первой успешной проверки.\n",
    "\n",
    "Но это так же и не обычное соревнование! Вы не проверяете ваш результат (предсказания), вместо этого проверочный скрипт запускает вашу программу, дает ей на стандартный ввод проверочные данные, и принимает предсказания от вашей программы на стандартном выводе.\n",
    "\n",
    "Внимательно прочитайте секции \"Обработка тестовых данных и формат вывода результатов\" и \"Проверка\" ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем предложенные пакеты\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os, sys\n",
    "import json\n",
    "import pickle\n",
    "from urllib.parse import urlparse, unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем свои пакеты\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных на вход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения работы вам следует тспользовать файл `/data/share/project01/gender_age_dataset.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/data/share/project01/gender_age_dataset.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Он содержит данные о посещении сайтов ~40 000 пользователей, при этом по некоторым из них (~ 35 000) известны их пол и возрастная категория, а по 5 000 - эта информация не известна. В файле есть 4 поля:\n",
    "* **gender** - пол, принимающий значения `M` (male - мужчина), `F` (female - женщина), `-` (пол неизвестен);\n",
    "* **age** - возраст, представленный в виде диапазона x-y (строковый тип), или `-` (возрастная категория неизвестна);\n",
    "* **uid** - идентификатор пользователя, строковая переменная;\n",
    "* **user_json** - поле json, в котором содержатся записи о посещении сайтов этим пользователем `(url, timestamp)`.\n",
    "\n",
    "Первое, что обычно делают в таких случаях, — исследуют имеющийся датасет и разбираются, какие же данные мы получили."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим весь датасет в pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.16 s, sys: 916 ms, total: 8.08 s\n",
      "Wall time: 8.07 s\n"
     ]
    }
   ],
   "source": [
    "%time df = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь попробуем понять, что у нас есть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>uid</th>\n",
       "      <th>user_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>18-24</td>\n",
       "      <td>d50192e5-c44e-4ae8-ae7a-7cfe67c8b777</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://zebra-zoya.ru/2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d502331d-621e-4721-ada2-5d30b2c3801f</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://sweetrading.ru/?p=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d50237ea-747e-48a2-ba46-d08e71dddfdb</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://ru.oriflame.com/pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d502f29f-d57a-46bf-8703-1cb5f8dcdf03</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://translate-tattoo.r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>&gt;=55</td>\n",
       "      <td>d503c3b2-a0c2-4f47-bb27-065058c73008</td>\n",
       "      <td>{\"visits\": [{\"url\": \"https://mail.rambler.ru/#...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender    age                                   uid  \\\n",
       "0      F  18-24  d50192e5-c44e-4ae8-ae7a-7cfe67c8b777   \n",
       "1      M  25-34  d502331d-621e-4721-ada2-5d30b2c3801f   \n",
       "2      F  25-34  d50237ea-747e-48a2-ba46-d08e71dddfdb   \n",
       "3      F  25-34  d502f29f-d57a-46bf-8703-1cb5f8dcdf03   \n",
       "4      M   >=55  d503c3b2-a0c2-4f47-bb27-065058c73008   \n",
       "\n",
       "                                           user_json  \n",
       "0  {\"visits\": [{\"url\": \"http://zebra-zoya.ru/2000...  \n",
       "1  {\"visits\": [{\"url\": \"http://sweetrading.ru/?p=...  \n",
       "2  {\"visits\": [{\"url\": \"http://ru.oriflame.com/pr...  \n",
       "3  {\"visits\": [{\"url\": \"http://translate-tattoo.r...  \n",
       "4  {\"visits\": [{\"url\": \"https://mail.rambler.ru/#...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что содержится в `user_json`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"visits\": [{\"url\": \"http://zebra-zoya.ru/200028-chehol-organayzer-dlja-macbook-11-grid-it.html?utm_campaign=397720794&utm_content=397729344&utm_medium=cpc&utm_source=begun\", \"timestamp\": 1419688144068}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426666298001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426666298000}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426661722001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426661722000}]}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].user_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что это некая сериализованная json-строка, которую можно легко разобрать через модуль `json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visits': [{'url': 'http://zebra-zoya.ru/200028-chehol-organayzer-dlja-macbook-11-grid-it.html?utm_campaign=397720794&utm_content=397729344&utm_medium=cpc&utm_source=begun',\n",
       "   'timestamp': 1419688144068},\n",
       "  {'url': 'http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story',\n",
       "   'timestamp': 1426666298001},\n",
       "  {'url': 'http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html',\n",
       "   'timestamp': 1426666298000},\n",
       "  {'url': 'http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story',\n",
       "   'timestamp': 1426661722001},\n",
       "  {'url': 'http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html',\n",
       "   'timestamp': 1426661722000}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df.iloc[0].user_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методом `pandas.DataFrame.apply` (хотя не только им) можно применить операцию десериализации json-строк ко всему датасету. Рекомендуем почитать [документацию по методу apply](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html).\n",
    "\n",
    "Работая с подобными операциями, обратите внимание на kwargs-аргумент `axis`. Часто, забыв его указать, вы примените операцию не к ряду (строке), а к столбцу, что вряд ли входит в ваши планы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _More EDA_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-34    15457\n",
       "35-44     9360\n",
       "-         5000\n",
       "18-24     4898\n",
       "45-54     4744\n",
       ">=55      1679\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review age column\n",
    "df.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    18698\n",
       "F    17440\n",
       "-     5000\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review gender column\n",
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОДХОДЫ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__URL structure:__ scheme://netloc/path?query\n",
    "\n",
    "__URL example:__ http://zebra-zoya.ru/200028-chehol-organayzer-dlja-macbook-11-grid-it.html?utm_campaign=397720794&utm_content=397729344&utm_medium=cpc&utm_source=begun\n",
    "\n",
    "| Подходы | Основная идея | Цепочка | Gender | Age | Результат |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| Cамый первый заход | Выстроить цепочку 'dataset' -> 'submission' | 'Standard' url2domain -> netlocs -> CountVectorizer -> bag of words -> RandomForest (100, max_depth=None) | 0.669 | 0.428 | >0.28 |\n",
    "| Улучшаем результат | XGBoost нам поможет | 'Standard' url2domain -> netlocs -> Count(Tfidf)Vectorizer -> bag of words -> **XGBoost (gender: 1000x6; age: 300x3)** | >0.68 | >0.44 | до 0.30 |\n",
    "| Пробуем другие модели | Что сможет embedding+LSTM? | 'Standard' url2domain -> netlocs -> **KerasTokenizer -> Embedding -> LSTM** | - | - | долго/ нет смысла |\n",
    "| Пробуем ещё модели | Что сможет обычная нейронная сеть? | 'Standard' url2domain -> netlocs -> KerasTokenizer -> **bag of words -> Dense Net** | - | - | overfitting/ мало данных |\n",
    "| Прорыв с новыми данными | Пришло понимание, что только данные нам помогут | **'Modified'** url2domain -> netlocs + **path/query** -> CountVectorizer -> bag of words -> XGBoost | >0.70 | >0.44 | >0.31 |\n",
    "| Попытка 'улучшить' данные | Add stop words, remove all digits, get hours as separate features, apply stemming, etc | 'Modified' url2domain + **timestamps** -> netlocs/path/query + **hour** -> **words pre-processing** -> CountVectorizer -> bag of words -> XGBoost | - | - | tradeoff gender vs age |\n",
    "| 'Кручининский' прорыв | Пришло понимание, что фильтр на test_df дает прорыв в результате | 'Modified' url2domain -> netlocs/path/query  -> CountVectorizer -> bag of words -> XGBoost + **test_df фильтруем по медиане кол-ва слов** | >0.70 | >0.44 | >0.36 |\n",
    "| Финализация | Отказ от stop words, remove digits, hours as features. Вместо этого hours added to bag of words + model tuning | **'Final'** url2domain -> netlocs/path/query -> CountVectorizer **(binary, min_df=6)** -> bag of words -> XGBoost **(gender: 1400x6; age: 350x4)** | ~0.705 | ~0.445 | ~0.37 val/ ~0.36 test |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очистка данных и feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка данных и генерация новых фич составит значительную часть вашей работы. Именно здесь вы и должны продемонстрировать знания и креативность: чем лучше окажутся ваши фичи и чем лучше сможете убрать шум из датасета, тем лучших результатов вы достигнете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из первых вещей, которые можно попробовать — это вытащить домены и использовать их в качестве признаков. Можно воспользоваться функцией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url2domain(url):\n",
    "    url = re.sub('(http(s)*://)+', 'http://', url)\n",
    "    parsed_url = urlparse(unquote(url.strip()))\n",
    "    if parsed_url.scheme not in ['http','https']:\n",
    "        return None\n",
    "    netloc = re.search(\"(?:www\\.)?(.*)\", parsed_url.netloc).group(1)\n",
    "    path = re.findall(\"([a-z]+[a-z0-9]+)\", parsed_url.path)\n",
    "    query = re.findall(\"([a-z]+[a-z0-9]+)\", parsed_url.query)\n",
    "    if path is not None:\n",
    "        path = \" \".join(path)\n",
    "        result = netloc + \"/\" + path\n",
    "    else:\n",
    "        result = netloc\n",
    "    if query is not None:\n",
    "        query = \" \".join(query)\n",
    "        result = result + \"?\" + query\n",
    "    if result is not None:\n",
    "        return result        #str(result.encode('utf8')).strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку эта часть и есть ваша работа, мы не станем раскрывать все секреты (хотя несколько советов мы всё же дали, посмотрите ниже в разделе Подсказки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Сделаем из записей о посещении сайтов документы для Bag of words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.1 s, sys: 2.55 s, total: 35.7 s\n",
      "Wall time: 35.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>uid</th>\n",
       "      <th>user_json</th>\n",
       "      <th>visits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>18-24</td>\n",
       "      <td>d50192e5-c44e-4ae8-ae7a-7cfe67c8b777</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://zebra-zoya.ru/2000...</td>\n",
       "      <td>[{'url': 'http://zebra-zoya.ru/200028-chehol-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d502331d-621e-4721-ada2-5d30b2c3801f</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://sweetrading.ru/?p=...</td>\n",
       "      <td>[{'url': 'http://sweetrading.ru/?p=900', 'time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d50237ea-747e-48a2-ba46-d08e71dddfdb</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://ru.oriflame.com/pr...</td>\n",
       "      <td>[{'url': 'http://ru.oriflame.com/products/prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>d502f29f-d57a-46bf-8703-1cb5f8dcdf03</td>\n",
       "      <td>{\"visits\": [{\"url\": \"http://translate-tattoo.r...</td>\n",
       "      <td>[{'url': 'http://translate-tattoo.ru/font-sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>&gt;=55</td>\n",
       "      <td>d503c3b2-a0c2-4f47-bb27-065058c73008</td>\n",
       "      <td>{\"visits\": [{\"url\": \"https://mail.rambler.ru/#...</td>\n",
       "      <td>[{'url': 'https://mail.rambler.ru/#/folder/', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender    age                                   uid  \\\n",
       "0      F  18-24  d50192e5-c44e-4ae8-ae7a-7cfe67c8b777   \n",
       "1      M  25-34  d502331d-621e-4721-ada2-5d30b2c3801f   \n",
       "2      F  25-34  d50237ea-747e-48a2-ba46-d08e71dddfdb   \n",
       "3      F  25-34  d502f29f-d57a-46bf-8703-1cb5f8dcdf03   \n",
       "4      M   >=55  d503c3b2-a0c2-4f47-bb27-065058c73008   \n",
       "\n",
       "                                           user_json  \\\n",
       "0  {\"visits\": [{\"url\": \"http://zebra-zoya.ru/2000...   \n",
       "1  {\"visits\": [{\"url\": \"http://sweetrading.ru/?p=...   \n",
       "2  {\"visits\": [{\"url\": \"http://ru.oriflame.com/pr...   \n",
       "3  {\"visits\": [{\"url\": \"http://translate-tattoo.r...   \n",
       "4  {\"visits\": [{\"url\": \"https://mail.rambler.ru/#...   \n",
       "\n",
       "                                              visits  \n",
       "0  [{'url': 'http://zebra-zoya.ru/200028-chehol-o...  \n",
       "1  [{'url': 'http://sweetrading.ru/?p=900', 'time...  \n",
       "2  [{'url': 'http://ru.oriflame.com/products/prod...  \n",
       "3  [{'url': 'http://translate-tattoo.ru/font-sele...  \n",
       "4  [{'url': 'https://mail.rambler.ru/#/folder/', ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразуем user_json в питоновские словари и нормализуем один уровень\n",
    "%time df['visits'] = json_normalize(df.user_json.apply(json.loads))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract info from 'url' and 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 1.04 s, total: 1min 58s\n",
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>18-24</td>\n",
       "      <td>[zebra-zoya.ru/chehol organayzer dlja macbook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>[sweetrading.ru/?/22, sweetrading.ru/?/22, swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>[ru.oriflame.com/products product?code/18, ru....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>[translate-tattoo.ru/font selection?hash c573a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>&gt;=55</td>\n",
       "      <td>[mail.rambler.ru/?/8, news.rambler.ru/?/8, mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender    age                                            domains\n",
       "0      F  18-24  [zebra-zoya.ru/chehol organayzer dlja macbook ...\n",
       "1      M  25-34  [sweetrading.ru/?/22, sweetrading.ru/?/22, swe...\n",
       "2      F  25-34  [ru.oriflame.com/products product?code/18, ru....\n",
       "3      F  25-34  [translate-tattoo.ru/font selection?hash c573a...\n",
       "4      M   >=55  [mail.rambler.ru/?/8, news.rambler.ru/?/8, mai..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вытаскиваем domains из списка словарей в список domains\n",
    "%time df['domains'] = df['visits'].apply(lambda x: [url2domain(item['url']) + \"/\" + \\\n",
    "                                                    str(pd.Timestamp(item['timestamp'], unit='ms').hour) for item in x])\n",
    "\n",
    "\n",
    "df[['gender', 'age', 'domains']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zebra-zoya.ru/chehol organayzer dlja macbook grid it html?utm campaign utm content utm medium cpc utm source begun/13',\n",
       " 'news.yandex.ru/yandsearch?cl4url chezasite com htc htc one m9 delay html lr rpt story/8',\n",
       " 'sotovik.ru/news htc one m9 zaderzhivaetsja html?/8',\n",
       " 'news.yandex.ru/yandsearch?cl4url chezasite com htc htc one m9 delay html lr rpt story/6',\n",
       " 'sotovik.ru/news htc one m9 zaderzhivaetsja html?/6']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domains'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 ms, sys: 264 ms, total: 564 ms\n",
      "Wall time: 562 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>18-24</td>\n",
       "      <td>zebra-zoya.ru/chehol organayzer dlja macbook g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25-34</td>\n",
       "      <td>sweetrading.ru/?/22 sweetrading.ru/?/22 sweetr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>ru.oriflame.com/products product?code/18 ru.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>25-34</td>\n",
       "      <td>translate-tattoo.ru/font selection?hash c573a5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>&gt;=55</td>\n",
       "      <td>mail.rambler.ru/?/8 news.rambler.ru/?/8 mail.r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender    age                                            domains\n",
       "0      F  18-24  zebra-zoya.ru/chehol organayzer dlja macbook g...\n",
       "1      M  25-34  sweetrading.ru/?/22 sweetrading.ru/?/22 sweetr...\n",
       "2      F  25-34  ru.oriflame.com/products product?code/18 ru.or...\n",
       "3      F  25-34  translate-tattoo.ru/font selection?hash c573a5...\n",
       "4      M   >=55  mail.rambler.ru/?/8 news.rambler.ru/?/8 mail.r..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Делаем из списка domains строки для Bag of words\n",
    "%time df['domains'] = df['domains'].apply(lambda x:' '.join(x))\n",
    "df[['gender', 'age', 'domains']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь можно удалить ненужные колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'uid', 'user_json', 'visits', 'domains'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'uid', 'visits', 'domains'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# можно удалить ненужные колонки\n",
    "df.drop(['user_json',], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деление на train и test сеты, обучение модели, предсказания для test-сета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь оценим размер нашего train и test сетов. Train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36138"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[~((df.gender == '-') & (df.age == '-'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.gender == '-') & (df.age == '-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41138"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) # Весь датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы очистили данные и сгенерировали признаки, которые можно дать на вход алгоритму, следующий этап — это разделить данные на тренировочную и тестовую выборки. Сохраните train и test выборки в отдельных файлах, используя метод `pandas.DataFrame.to_csv`. Либо просто сделайте два датафрейма: `train_df` и `test_df`. Обучите модель на ваш выбор, оцените результат, подумайте, как можно его улучшить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36138, 5), (5000, 5))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.query(\"~(gender=='-' & age=='-')\")\n",
    "test_df = df.query(\"gender=='-' & age=='-'\")\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.8 s, sys: 884 ms, total: 34.7 s\n",
      "Wall time: 34.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=6,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1 = CountVectorizer(binary=True, min_df=6)\n",
    "%time vectorizer1.fit(train_df.domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76775"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(vectorizer1.vocabulary_.keys())\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vectorizer1.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>uid</th>\n",
       "      <th>visits</th>\n",
       "      <th>domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36206</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bdb2df89-4bcd-410f-8388-e18af8bfc6a4</td>\n",
       "      <td>[{'url': 'http://1-veda.info/india/gokarna-kar...</td>\n",
       "      <td>1-veda.info/india gokarna karnataka html?/9 ik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40263</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>b28429bd-ca51-4553-8259-56137cdd7ec5</td>\n",
       "      <td>[{'url': 'http://1000cxem.com/?', 'timestamp':...</td>\n",
       "      <td>1000cxem.com/?/12 yandex.ru/clck jsredir?from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39243</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>b19ecd12-40bc-4fc4-8a3d-bf25f80eebd3</td>\n",
       "      <td>[{'url': 'http://www.1000v1.ru/catalog/163/det...</td>\n",
       "      <td>1000v1.ru/catalog detail?/20 1000v1.ru/catalog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38424</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>dcb9a4d4-8997-4791-8845-54119e0ab4b5</td>\n",
       "      <td>[{'url': 'http://www.1000v1.ru/catalog/49/deta...</td>\n",
       "      <td>1000v1.ru/catalog detail?/9 1000v1.ru/catalog ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39120</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>b1013d93-f859-4e8f-8d6c-0b156acc0bbc</td>\n",
       "      <td>[{'url': 'http://www.1001eda.com/dieta-pri-pan...</td>\n",
       "      <td>1001eda.com/dieta pri pankreatite?/10 wh-lady....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38167</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>ed86a278-2715-4672-b10f-ced066e19b0f</td>\n",
       "      <td>[{'url': 'http://www.1001eda.com/grechka-v-gor...</td>\n",
       "      <td>1001eda.com/grechka gorshochkax?/11 mixiplay.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39199</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>b1633d95-0532-4d5a-a20c-05a6e6600642</td>\n",
       "      <td>[{'url': 'http://www.1001eda.com/gribnoj-rulet...</td>\n",
       "      <td>1001eda.com/gribnoj rulet lavashe?/12 pillsman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37500</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0278ec6f-c9be-4896-8606-6b03f9ff5a04</td>\n",
       "      <td>[{'url': 'http://www.1001eda.com/kofejnyj-keks...</td>\n",
       "      <td>1001eda.com/kofejnyj keks multivarke?/5 yandex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36467</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>47d1f472-4c3d-4914-8e55-2b726de345cd</td>\n",
       "      <td>[{'url': 'http://www.1001eda.com/plov-v-multiv...</td>\n",
       "      <td>1001eda.com/plov multivarke recept poshagovym ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40114</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>89f3f966-800f-4ac4-908e-9708e916a561</td>\n",
       "      <td>[{'url': 'http://www.1001eda.com/prostoj-tort-...</td>\n",
       "      <td>1001eda.com/prostoj tort iz gotovyx biskvitnyx...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender age                                   uid  \\\n",
       "36206      -   -  bdb2df89-4bcd-410f-8388-e18af8bfc6a4   \n",
       "40263      -   -  b28429bd-ca51-4553-8259-56137cdd7ec5   \n",
       "39243      -   -  b19ecd12-40bc-4fc4-8a3d-bf25f80eebd3   \n",
       "38424      -   -  dcb9a4d4-8997-4791-8845-54119e0ab4b5   \n",
       "39120      -   -  b1013d93-f859-4e8f-8d6c-0b156acc0bbc   \n",
       "38167      -   -  ed86a278-2715-4672-b10f-ced066e19b0f   \n",
       "39199      -   -  b1633d95-0532-4d5a-a20c-05a6e6600642   \n",
       "37500      -   -  0278ec6f-c9be-4896-8606-6b03f9ff5a04   \n",
       "36467      -   -  47d1f472-4c3d-4914-8e55-2b726de345cd   \n",
       "40114      -   -  89f3f966-800f-4ac4-908e-9708e916a561   \n",
       "\n",
       "                                                  visits  \\\n",
       "36206  [{'url': 'http://1-veda.info/india/gokarna-kar...   \n",
       "40263  [{'url': 'http://1000cxem.com/?', 'timestamp':...   \n",
       "39243  [{'url': 'http://www.1000v1.ru/catalog/163/det...   \n",
       "38424  [{'url': 'http://www.1000v1.ru/catalog/49/deta...   \n",
       "39120  [{'url': 'http://www.1001eda.com/dieta-pri-pan...   \n",
       "38167  [{'url': 'http://www.1001eda.com/grechka-v-gor...   \n",
       "39199  [{'url': 'http://www.1001eda.com/gribnoj-rulet...   \n",
       "37500  [{'url': 'http://www.1001eda.com/kofejnyj-keks...   \n",
       "36467  [{'url': 'http://www.1001eda.com/plov-v-multiv...   \n",
       "40114  [{'url': 'http://www.1001eda.com/prostoj-tort-...   \n",
       "\n",
       "                                                 domains  \n",
       "36206  1-veda.info/india gokarna karnataka html?/9 ik...  \n",
       "40263  1000cxem.com/?/12 yandex.ru/clck jsredir?from ...  \n",
       "39243  1000v1.ru/catalog detail?/20 1000v1.ru/catalog...  \n",
       "38424  1000v1.ru/catalog detail?/9 1000v1.ru/catalog ...  \n",
       "39120  1001eda.com/dieta pri pankreatite?/10 wh-lady....  \n",
       "38167  1001eda.com/grechka gorshochkax?/11 mixiplay.c...  \n",
       "39199  1001eda.com/gribnoj rulet lavashe?/12 pillsman...  \n",
       "37500  1001eda.com/kofejnyj keks multivarke?/5 yandex...  \n",
       "36467  1001eda.com/plov multivarke recept poshagovym ...  \n",
       "40114  1001eda.com/prostoj tort iz gotovyx biskvitnyx...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sort_values(by='domains')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.domains.apply(lambda x: len(x.split(\" \"))).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 724 ms, sys: 240 ms, total: 964 ms\n",
      "Wall time: 974 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>uid</th>\n",
       "      <th>visits</th>\n",
       "      <th>domains</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36138</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd7a30e1-a25d-4cbf-a03f-61748cbe540e</td>\n",
       "      <td>[{'url': 'http://www.interfax.ru/business/4146...</td>\n",
       "      <td>interfax.ru/business?/14 amerikan-gruzovik.ru/...</td>\n",
       "      <td>10432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36139</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd7a6f52-45db-49bf-90f2-a3b07a9b7bcd</td>\n",
       "      <td>[{'url': 'https://www.packagetrackr.com/track/...</td>\n",
       "      <td>packagetrackr.com/track ups?/6 packagetrackr.c...</td>\n",
       "      <td>7695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36140</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd7a7fd9-ab06-42f5-bf0f-1cbb0463004c</td>\n",
       "      <td>[{'url': 'http://www.mk.ru/incident/2015/02/27...</td>\n",
       "      <td>mk.ru/incident latviya podnyala vozdukh istreb...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36141</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd7c5d7a-0def-41d1-895f-fdb96c56c2d4</td>\n",
       "      <td>[{'url': 'http://www.24open.ru/user/elena80204...</td>\n",
       "      <td>24open.ru/user elena8020445?/3 ohotniki.ru/wea...</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36142</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd7e54a2-0215-45cb-a869-9efebf250e38</td>\n",
       "      <td>[{'url': 'http://www.dns-shop.ru/catalog/i1728...</td>\n",
       "      <td>dns-shop.ru/catalog i172806 tverdotelnyj nakop...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36143</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd7e9797-4cdb-46e1-a540-f3ea010605ad</td>\n",
       "      <td>[{'url': 'http://news.meta.ua/cluster:41878362...</td>\n",
       "      <td>news.meta.ua/cluster sevastopole nashli dokhlu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36144</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd7e9ec7-fb67-45eb-8ad3-209d01d15ae6</td>\n",
       "      <td>[{'url': 'http://dynamobryansk.forum24.ru/', '...</td>\n",
       "      <td>dynamobryansk.forum24.ru/?/15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36145</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd8056df-cc25-4b63-bc12-a46f888baa49</td>\n",
       "      <td>[{'url': 'http://www.2mm.ru/mzdorovie/634/gerp...</td>\n",
       "      <td>2mm.ru/mzdorovie gerpes vooruzhen ochen opasen...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36146</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd818690-73d2-445d-be5d-5c8f748dbb19</td>\n",
       "      <td>[{'url': 'http://www.lacywear.ru/goods/categor...</td>\n",
       "      <td>lacywear.ru/goods category?utm source yandex m...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36147</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd81e006-f059-4cdd-b716-3467c78d1312</td>\n",
       "      <td>[{'url': 'http://nn.domru.ru/', 'timestamp': 1...</td>\n",
       "      <td>nn.domru.ru/?/16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36148</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd81e64a-bfa3-4147-b094-e3d248c44e9a</td>\n",
       "      <td>[{'url': 'http://cache.betweendigital.com/code...</td>\n",
       "      <td>cache.betweendigital.com/code bidder html?user...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36149</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd82fee4-afb3-4085-a5da-9bce2b5523ef</td>\n",
       "      <td>[{'url': 'http://apostrophe.com.ua/news/societ...</td>\n",
       "      <td>apostrophe.com.ua/news society accidents kreml...</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36150</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd83400b-abe2-42fd-b73a-4edb886fb036</td>\n",
       "      <td>[{'url': 'http://index.ru/widget?period=day&amp;ca...</td>\n",
       "      <td>index.ru/widget?period day categories news acc...</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36151</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd843c8c-dbba-4ecb-b5e8-45ba8c31584e</td>\n",
       "      <td>[{'url': 'http://katushka.net/advert.php?id=24...</td>\n",
       "      <td>katushka.net/advert php?id x400 category/15 ka...</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36152</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bd86d250-a6ee-41fe-af7e-c972fd438b70</td>\n",
       "      <td>[{'url': 'http://www.sq.com.ua/', 'timestamp':...</td>\n",
       "      <td>sq.com.ua/?/16 news.yandex.ua/yandsearch?cl4ur...</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender age                                   uid  \\\n",
       "36138      -   -  bd7a30e1-a25d-4cbf-a03f-61748cbe540e   \n",
       "36139      -   -  bd7a6f52-45db-49bf-90f2-a3b07a9b7bcd   \n",
       "36140      -   -  bd7a7fd9-ab06-42f5-bf0f-1cbb0463004c   \n",
       "36141      -   -  bd7c5d7a-0def-41d1-895f-fdb96c56c2d4   \n",
       "36142      -   -  bd7e54a2-0215-45cb-a869-9efebf250e38   \n",
       "36143      -   -  bd7e9797-4cdb-46e1-a540-f3ea010605ad   \n",
       "36144      -   -  bd7e9ec7-fb67-45eb-8ad3-209d01d15ae6   \n",
       "36145      -   -  bd8056df-cc25-4b63-bc12-a46f888baa49   \n",
       "36146      -   -  bd818690-73d2-445d-be5d-5c8f748dbb19   \n",
       "36147      -   -  bd81e006-f059-4cdd-b716-3467c78d1312   \n",
       "36148      -   -  bd81e64a-bfa3-4147-b094-e3d248c44e9a   \n",
       "36149      -   -  bd82fee4-afb3-4085-a5da-9bce2b5523ef   \n",
       "36150      -   -  bd83400b-abe2-42fd-b73a-4edb886fb036   \n",
       "36151      -   -  bd843c8c-dbba-4ecb-b5e8-45ba8c31584e   \n",
       "36152      -   -  bd86d250-a6ee-41fe-af7e-c972fd438b70   \n",
       "\n",
       "                                                  visits  \\\n",
       "36138  [{'url': 'http://www.interfax.ru/business/4146...   \n",
       "36139  [{'url': 'https://www.packagetrackr.com/track/...   \n",
       "36140  [{'url': 'http://www.mk.ru/incident/2015/02/27...   \n",
       "36141  [{'url': 'http://www.24open.ru/user/elena80204...   \n",
       "36142  [{'url': 'http://www.dns-shop.ru/catalog/i1728...   \n",
       "36143  [{'url': 'http://news.meta.ua/cluster:41878362...   \n",
       "36144  [{'url': 'http://dynamobryansk.forum24.ru/', '...   \n",
       "36145  [{'url': 'http://www.2mm.ru/mzdorovie/634/gerp...   \n",
       "36146  [{'url': 'http://www.lacywear.ru/goods/categor...   \n",
       "36147  [{'url': 'http://nn.domru.ru/', 'timestamp': 1...   \n",
       "36148  [{'url': 'http://cache.betweendigital.com/code...   \n",
       "36149  [{'url': 'http://apostrophe.com.ua/news/societ...   \n",
       "36150  [{'url': 'http://index.ru/widget?period=day&ca...   \n",
       "36151  [{'url': 'http://katushka.net/advert.php?id=24...   \n",
       "36152  [{'url': 'http://www.sq.com.ua/', 'timestamp':...   \n",
       "\n",
       "                                                 domains  count  \n",
       "36138  interfax.ru/business?/14 amerikan-gruzovik.ru/...  10432  \n",
       "36139  packagetrackr.com/track ups?/6 packagetrackr.c...   7695  \n",
       "36140  mk.ru/incident latviya podnyala vozdukh istreb...     58  \n",
       "36141  24open.ru/user elena8020445?/3 ohotniki.ru/wea...    526  \n",
       "36142  dns-shop.ru/catalog i172806 tverdotelnyj nakop...     77  \n",
       "36143  news.meta.ua/cluster sevastopole nashli dokhlu...      9  \n",
       "36144                      dynamobryansk.forum24.ru/?/15      1  \n",
       "36145  2mm.ru/mzdorovie gerpes vooruzhen ochen opasen...     14  \n",
       "36146  lacywear.ru/goods category?utm source yandex m...     49  \n",
       "36147                                   nn.domru.ru/?/16      1  \n",
       "36148  cache.betweendigital.com/code bidder html?user...     61  \n",
       "36149  apostrophe.com.ua/news society accidents kreml...    413  \n",
       "36150  index.ru/widget?period day categories news acc...    683  \n",
       "36151  katushka.net/advert php?id x400 category/15 ka...    266  \n",
       "36152  sq.com.ua/?/16 news.yandex.ua/yandsearch?cl4ur...   4062  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_df['count'] = test_df.domains.apply(lambda x: len([domain for domain in x.split()]))\n",
    "test_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2503, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.query('count >= count.median()').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Обучение модели\n",
    "\n",
    "Обучите модель на ваш выбор, оцените результат, подумайте, как можно его улучшить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Predict Gender XGBoost_\n",
    "\n",
    "| vectorizer | n_estimators | max_depth | lr | score | current leader\n",
    "| :--- | :--- | --- | --- | --- | --- |\n",
    "| CountVectorizer() | 1000 | 6 | 0.1 | 0.68545 |\n",
    "| CountVectorizer(binary=True) | 1000 | 6 | 0.1 | 0.68612 |\n",
    "| TfidfVectorizer(norm='l2') | 1000 | 6 | 0.1 | 0.68258 |\n",
    "| TfidfVectorizer(norm=None) | 1000 | 6 | 0.1 | 0.68554 |\n",
    "| TfidfVectorizer(binary=True, norm=None) + path | 1000 | 6 | 0.1 | 0.70170 | \n",
    "| 'hours' + 'words'/TfidfVectorizer(binary=True, norm=None) + path | 1000 | 6 | 0.1 | 0.70067 |\n",
    "| 'hours' + 'words'/TfidfVectorizer(norm=None) + path | 1000 | 6 | 0.1 | 0.70167 |\n",
    "| 'hours' + 'words'/CountVectorizer(binary=True, min_df=5) + path?query | 1000 | 6 | 0.1 | 0.70192 | \n",
    "| ~~'hours'~~ + 'words'/CountVectorizer(binary=True, min_df=5) + path?query | 1000 | 6 | 0.1 | 0.70349 | submitted\n",
    "| 'words'/CountVectorizer(binary=True, min_df=5) + path?query + cyrillic | 1000 | 6 | 0.1 | 0.70264 | \n",
    "| 'words'/CountVectorizer(binary=True, min_df=5) + path?query + cyrillic + stemmer_eng_rus | 1000 | 6 | 0.1 | 0.70562 |\n",
    "| 'words'/CountVectorizer(binary=True, min_df=5) + path?query + cyrillic + stemmer_rus | 1000 | 6 | 0.1 | 0.70668 | !!!\n",
    "| 'words'/CountVectorizer(binary=True, min_df=5) + path?query + cyrillic + ~~stemmer_rus~~ ~~stop_words~~ | 1000 | 6 | 0.1 | 0.70239 | \n",
    "| 'words'/CountVectorizer(binary=True, min_df=5) + path?query + cyrillic + ~~stemmer_rus~~ + stop_words | 1000 | 6 | 0.1 | 0.70239 |\n",
    "| 'words'/CountVectorizer(binary=True, min_df=5) + path?query + cyrillic + stemmer_rus + ~~stop_words~~ | 1000 | 6 | 0.1 | 0.70495 |\n",
    "| 'words' as above + path?query + cyrillic + stemmer_rus + stop_words-middle | 1000 | 6 | 0.1 | 0.70507 |\n",
    "| 'words' as above + path?query + cyrillic + stemmer_rus + stop_words-small+<15 | 1000 | 6 | 0.1 | 0.70356 |\n",
    "| 'words' as above + path?query + cyrillic + stop_words-small | 1000 | 6 | 0.1 | 0.70280 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1000 | 6 | 0.1 | 0.69743 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=5) | 1000 | 6 | 0.1 | 0.69610 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1100 | 6 | 0.1 | 0.69754 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1200 | 6 | 0.1 | 0.69821 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1300 | 6 | 0.1 | 0.69893 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1400 | 6 | 0.1 | 0.69840 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1500 | 6 | 0.1 | 0.69818 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1300 | 5 | 0.1 | 0.69650 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1300 | 7 | 0.1 | 0.69657 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) | 1350 | 6 | 0.1 | 0.69810 |\n",
    "| 'domains'/'full path'/'hour' + CountVect(binary, min_df=6) | 1300 | 6 | 0.1 | 0.70510 | !!!\n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) | 1300 | 6 | 0.1 | 0.70421 | submitted\n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) | 1200 | 6 | 0.1 | 0.70371 |\n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) | 1400 | 6 | 0.1 | 0.70504 | submitted\n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) | 1500 | 6 | 0.1 | 0.70457 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Pipeline(steps=[\n",
    "    ('vectorizer', CountVectorizer(binary=True, min_df=6)),\n",
    "    ('clf_xgb1', xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1400, verbosity=1, \n",
    "                                   objective='binary:logistic', n_jobs=-1))], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 11.7 s, total: 13.1 s\n",
      "Wall time: 5min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7037192041457807"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model and compute the cross-validation score\n",
    "%time scores_xgb_gender = cross_val_score(p1, train_df['domains'].values, y=train_df['gender'].values, cv=3, n_jobs=-1, verbose=1)\n",
    "scores_xgb_gender.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=  35.3s\n",
      "[Pipeline] .......... (step 2 of 2) Processing clf_xgb1, total= 2.1min\n",
      "CPU times: user 1h 12min 44s, sys: 5min 29s, total: 1h 18min 14s\n",
      "Wall time: 2min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=True,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=6,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabular...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "                               learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=1400, n_jobs=-1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=True, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline for saving its parameters\n",
    "%time p1.fit(train_df['domains'].values, train_df['gender'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Predict Age XGBoost_\n",
    "\n",
    "| vectorizer | n_estimators | max_depth | lr | score | current leader\n",
    "| :--- | --- | --- | --- | --- | --- |\n",
    "| CountVectorizer() | 300 | 3 | 0.1 | 0.44388 |\n",
    "| CountVectorizer(binary=True) | 300 | 3 | 0.1 | 0.44385 |\n",
    "| TfidfVectorizer() | 300 | 3 | 0.1 | 0.44227 |\n",
    "| TfidfVectorizer(norm=None) | 300 | 3 | 0.1 | 0.44391 |\n",
    "| TfidfVectorizer(norm=None)+stop_words | 300 | 4 | 0.1 | 0.44316 |\n",
    "| TfidfVectorizer(norm=None)+stop_words | 300 | 3 | 0.1 | 0.44382 |\n",
    "| TfidfVectorizer(binary=True, norm=None)+stop_words_ex_digits | 300 | 3 | 0.1 | 0.44333 |\n",
    "| TfidfVectorizer(norm=None)+stop_words_ex_digits | 300 | 3 | 0.1 | 0.44333 |\n",
    "| TfidfVectorizer(norm=None)+path+stop_words_ex_digits | 300 | 3 | 0.1 | 0.44197 |\n",
    "| TfidfVectorizer(binary=True, norm=None)+path+stop_words_ex_digits | 300 | 4 | 0.1 | 0.44241 | \n",
    "| 'hours' + 'words'/TfidfVectorizer(norm=None)+path+stop_words_ex_digits | 300 | 4 | 0.1 | 0.44044 |\n",
    "| 'hours' + 'words'/TfidfVectorizer(norm=None)+path+stop_words_ex_digits | 300 | 3 | 0.1 | 0.44147 |\n",
    "| 'hours' + 'words'/CountVectorizer(binary=True, min_df=5)+path?query+stop_words | 300 | 3 | 0.1 | 0.44269 |\n",
    "| 'hours' + 'words'/as above + OneVsRestClassifier(XGBClassifier) | 300 | 3 | 0.1 | 0.44255 | \n",
    "| 'hours' + 'words'/as above + OneVsRestClassifier(XGBClassifier) | 300 | 4 | 0.1 | 0.44391 |  \n",
    "| ~~'hours'~~ + 'words'/as above + OneVsRestClassifier(XGBClassifier) | 300 | 4 | 0.1 | 0.44440 | submitted \n",
    "| 'words'/as above + OneVsRestClassifier(XGBClassifier) + cyrillic | 300 | 4 | 0.1 | 0.44446 | \n",
    "| 'words'/as above + OneVsRestClassifier(XGBClassifier) + cyrillic + ~~stop_words~~ | 300 | 4 | 0.1 | 0.44471 | \n",
    "| 'words'/as above + OneVsRestClassifier(XGBClassifier) + cyrillic + stop_words[small] | 300 | 4 | 0.1 | 0.44490 | !!!\n",
    "| 'words'/as above + OneVsRestClassifier(XGBClassifier) + cyrillic + stemmer_rus +~~stop_words~~ | 300 | 4 | 0.1 | 0.44371 | \n",
    "| 'words'/as above + OneVsRestClassifier(XGBClassifier) + cyrillic + stemmer + stop_words-middle | 300 | 4 | 0.1 | 0.44316 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=5) + OneVsRest | 300 | 4 | 0.1 | 0.44476 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 300 | 4 | 0.1 | 0.44476 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 400 | 4 | 0.1 | 0.44496 | \n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 500 | 4 | 0.1 | 0.44457 |\n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 350 | 4 | 0.1 | 0.44509 | \n",
    "| 'domains'/'1st word path'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 370 | 4 | 0.1 | 0.44512 | \n",
    "| 'domains'/'full path'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 370 | 4 | 0.1 | 0.44388 | \n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 370 | 4 | 0.1 | 0.44523 | submitted \n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 300 | 4 | 0.1 | 0.44529 |\n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 400 | 4 | 0.1 | 0.44551 | !!!\n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 450 | 4 | 0.1 | 0.44548 |\n",
    "| 'domains'/'full path' + 'query'/'hour' + CountVect(binary, min_df=6) + OneVsRest | 450 | 4 | 0.1 | 0.44518 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = Pipeline(steps=\n",
    "              [('vectorizer', CountVectorizer(binary=True, min_df=6)),\n",
    "               ('clf_xgb2', OneVsRestClassifier(xgb.XGBClassifier(max_depth=4, learning_rate=0.1, n_estimators=350, verbosity=1, \n",
    "                                              objective='binary:logistic', scale_pos_weight=1), n_jobs=-1)) \n",
    "              ], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 56 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 8.7 s, total: 9.91 s\n",
      "Wall time: 2min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4451816709900922"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model and compute the cross-validation score\n",
    "%time scores_xgb_age = cross_val_score(p2, train_df['domains'].values, y=train_df['age'].values, cv=3, n_jobs=-1, verbose=1)\n",
    "scores_xgb_age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=  34.9s\n",
      "[Pipeline] .......... (step 2 of 2) Processing clf_xgb2, total= 1.5min\n",
      "CPU times: user 34 s, sys: 7.98 s, total: 42 s\n",
      "Wall time: 2min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=True,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=6,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabular...\n",
       "                 OneVsRestClassifier(estimator=XGBClassifier(base_score=0.5,\n",
       "                                                             booster='gbtree',\n",
       "                                                             colsample_bylevel=1,\n",
       "                                                             colsample_bytree=1,\n",
       "                                                             gamma=0,\n",
       "                                                             learning_rate=0.1,\n",
       "                                                             max_delta_step=0,\n",
       "                                                             max_depth=4,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=None,\n",
       "                                                             n_estimators=350,\n",
       "                                                             n_jobs=1,\n",
       "                                                             nthread=None,\n",
       "                                                             objective='binary:logistic',\n",
       "                                                             random_state=0,\n",
       "                                                             reg_alpha=0,\n",
       "                                                             reg_lambda=1,\n",
       "                                                             scale_pos_weight=1,\n",
       "                                                             seed=None,\n",
       "                                                             silent=True,\n",
       "                                                             subsample=1,\n",
       "                                                             verbosity=1),\n",
       "                                     n_jobs=-1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline for saving its parameters\n",
    "%time p2.fit(train_df['domains'].values, train_df['age'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучать модель вы можете в ноутбуке - это удобно. А после того как модель обучилась и стала выдавать приемлемое качество на вашей валидационной выборке, сохраните ее в отдельном файле (например, используя pickle):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Сохранить модель, которая содержится в переменной vectorizer\n",
    "#Установите правильные атрибуты файла модели, чтобы он мог быть считан проверочным скриптом:\n",
    "model_file_gender = \"project01_model_gender.pickle\"\n",
    "\n",
    "with open(os.environ['HOME'] + '/project1/' + model_file_gender, 'wb') as f:\n",
    "    pickle.dump(p1, f)\n",
    "    os.chmod(os.environ['HOME'] + '/project1/' + model_file_gender, 0o644)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Сохранить модель, которая содержится в переменной vectorizer\n",
    "#Установите правильные атрибуты файла модели, чтобы он мог быть считан проверочным скриптом:\n",
    "model_file_age = \"project01_model_age.pickle\"\n",
    "\n",
    "with open(os.environ['HOME'] + '/project1/' + model_file_age, 'wb') as f:\n",
    "    pickle.dump(p2, f)\n",
    "    os.chmod(os.environ['HOME'] + '/project1/' + model_file_age, 0o644)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, не забудьте сохранить и код генерации признаков и обучения модели - это нужно для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка тестовых данных и формат вывода результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо того, что у вас должна получиться точная модель, вам нужно уложиться в SLA (service-level agreement). Всё почти как по-настоящему. Результатом вашей работы в данном случае будет не выходной файл, в котором вы всё посчитали для скрытой выборки, а скрипт, который мы будем запускать и проверять SLA и точность.\n",
    "\n",
    "Создайте в корне своей домашней директории файл `project01_gender-age.py`. \n",
    "\n",
    "Назначте ему нужные права: `chmod 755 project01_gender-age.py`.\n",
    "\n",
    "Вот фрагмент кода, который считывает данные из потока стандартного ввода:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/opt/anaconda/envs/bd9/bin/python\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "columns=['gender','age','uid','user_json']\n",
    "\n",
    "df = pd.read_table(\n",
    "    sys.stdin, \n",
    "    sep='\\t', \n",
    "    header=None, \n",
    "    names=columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее вы должны применить все те же самые преобразования данных, которые (возможно) применили к обучающей выборке.\n",
    "Затем считываете модель:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#считать модель из файла в переменную vectorizer\n",
    "import pickle\n",
    "\n",
    "model_file = \"project01_model.pickle\"\n",
    "p1 = pickle.load(open(model_file, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Путь к модели необходимо указывать относительно вашей домашней директории. Например, если в директории `name.surname` есть папка `project01`, в которой лежит модель `project01_model.pickle`, то путь к модели в скрипте будет выглядеть как `project01/project01_model.pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача вашего скрипта сделать предсказание по всем полученным строкам и выдать результат в формате json. В файле должны быть только те пользователи, у которых пол и возрастная категория изначально неизвестны, и они должны быть **отсортированы по UID по возрастанию значений лексикографически.** Пример вывода указан ниже."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output = output[['uid', 'gender', 'age']]\n",
    "output.sort_values(by='uid',axis = 0, ascending = True, inplace = True)\n",
    "sys.stdout.write(output.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для самопроверки вы можете локально оттестировать свой скрипт, используя следующую команду:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!tail -n1000 /data/share/project01/gender_age_dataset.txt | python3 ../project01_gender-age.py > output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсказки\n",
    "\n",
    "1. Есть много различных способов решить данную задачу: можно просто хорошо поработать с урлами и доменами, можно пропарсить содержимое этих урлов (заголовки, текст и т.д.) и воспользоваться неким векторизатором типа TF\\*IDF для генерации дополнительных фич, которые уже в дальнейшем вы подадите на вход ML-алгоритму, можно сделать тематическое моделирование (LDA, BigARTM) сайтов и использовать одну или несколько тем в качестве фич.\n",
    "\n",
    "2. Возможно, что данные грязные и их нужно дополнительно обработать. Спецсимволы, кириллические домены? Уделите этому этапу достаточно времени: здесь чистота датасета важнее, чем выбор алгоритма.\n",
    "\n",
    "3. Часто бывает, что лучшее решение с точки зрения результата — оно же самое простое. Попробуйте сначала простые способы, простые алгоритмы, прежде чем переходить к тяжёлой артиллерии. Один из вариантов — начать с небольшого RandomForest.\n",
    "\n",
    "4. Вам почти наверняка понадобится что-то из пакета sklearn. [Документация](http://scikit-learn.org/stable/user_guide.html) — ваш лучший друг.\n",
    "\n",
    "5. Вы можете сначала предсказать пол, а затем возраст, либо сразу и то, и другое. Экспериментируйте.\n",
    "\n",
    "6. Объединяйтесь в команды. Так гораздо веселее и интереснее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка\n",
    "Проверка осуществляется из [Личного кабинета](http://lk.newprolab.com/lab/project1). До дедлайна вы будете проверять работу своего скрипта на валидационной выборке (2 000 записей). При наступлении дедлайна мы автоматически пересчитаем модели по скрытой тестовой выборке (3 000 записей). Это и будет финальным результатом.\n",
    "\n",
    "* В поле `part of users with predicted gender + age` - указана доля пользователей, которая была предсказана от общего числа неизвестных пользователей (пример: по 3 000 был сделан прогноз, а всего было неизвестно 5 000, чекер выдаст 0.6).\n",
    "\n",
    "* В поле `correctly predicted users / total number of users` - указана доля пользователей, которая была правильно предсказана (совпадает и пол, и возраст) от общего числа всех пользователей (пример: по 3 000 был сделан прогноз, правильно было спрогнозировано 1 500, а всего было неизвестно 5 000, чекер выдаст 0.3)\n",
    "\n",
    "* В поле `correctly predicted users / number of predicted users` - указана доля пользователей, которая была правильно предсказана (совпадает и пол, и возраст) от общего числа предсказанных пользователей (пример: по 3 000 был сделан прогноз, из них правильно предсказано 1 500, чекер выдаст 0.5).\n",
    "\n",
    "**Важное замечание!** Вы должны дать прогноз хотя бы по 50% пользователей, у которых изначально не указан пол и возрастная категория. Иными словами, вы можете оставить неопределенными не более 50% изначально неопределенных пользователей.\n",
    "\n",
    "**Если доля в последнем поле превысит порог 0.28, то проект будет засчитан, при условии что выполнен SLA в 0.04 секунды на каждого пользователя (т.е. на каждую строчку тестового датасета)**\n",
    "\n",
    "Лучшей команде, набравшей максимальный результат, мы подарим специальный приз, о котором скажем позднее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.np_utils import to_categorical # to convert to one-hot-encoding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define mane parameters of the input\n",
    "vocab = 10000      # number of words in vocabulary\n",
    "embed_size = 128   # embedding dimension\n",
    "length = 256       # max number of words in sentence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def tokenize_texts_to_sequences(train_text, test_text, vocab, length):\n",
    "    tokenizer = Tokenizer(num_words=vocab)\n",
    "    tokenizer.fit_on_texts(train_text)\n",
    "    # transform sentences to sequences of integers (vocab indices)\n",
    "    X_train = tokenizer.texts_to_sequences(train_text)\n",
    "    X_test = tokenizer.texts_to_sequences(test_text)\n",
    "    # pad sequences to one length\n",
    "    X_train = pad_sequences(X_train, maxlen=length, padding='post')\n",
    "    X_test = pad_sequences(X_test, maxlen=length, padding='post')\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time X_train_seq, X_test_seq = tokenize_texts_to_sequences(train_df.tokens, test_df.tokens, vocab=vocab, length=length)\n",
    "X_train_seq.shape, X_test_seq.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def tokenize_texts_to_matrix(train_text, test_text, vocab):\n",
    "    tokenizer = Tokenizer(num_words=vocab)\n",
    "    tokenizer.fit_on_texts(train_text)\n",
    "    # transform words to one-hot-vectors of length=vocab\n",
    "    X_train = tokenizer.texts_to_matrix(train_text, mode='binary')\n",
    "    X_test = tokenizer.texts_to_matrix(test_text, mode='binary')\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time X_train_mat, X_test_mat = tokenize_texts_to_matrix(train_df.tokens, test_df.tokens, vocab=vocab)\n",
    "X_train_mat.shape, X_test_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "le_gender = LabelEncoder()\n",
    "y_gender = le_gender.fit_transform(train_df.gender.values)\n",
    "le_gender.classes_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_gender[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Embedding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Function to create model\n",
    "def model_gender_embed(vocab, embed_size, length):\n",
    "    # create model with embedding input layer\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab, output_dim=embed_size, input_length=length))\n",
    "    model.add(Flatten())\n",
    "    # first dense layer\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(1e-2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.0))\n",
    "    # second dense layer\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(1e-2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.0))\n",
    "    # output layer\n",
    "    model.add(Dense(1), activation='sigmoid')\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model11 = model_gender_embed(vocab=vocab, embed_size=embed_size, length=length)\n",
    "model11.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', patience=1, factor=0.5, min_lr=1e-7, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time History11 = model11.fit(X_train_seq, y_gender, batch_size=256, epochs=5, \\\n",
    "                              validation_split=0.2, callbacks=[lr_decay], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Bag of words"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Function to create model\n",
    "def model_gender(vocab):\n",
    "    model = Sequential()\n",
    "    # input dense layer\n",
    "    model.add(Dense(16, input_dim=vocab, activation='relu',  kernel_regularizer=l2(1)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.5))\n",
    "    # second dense layer\n",
    "    model.add(Dense(8, activation='relu',  kernel_regularizer=l2(1)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.5))\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(1)))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model12 = model_gender(vocab=vocab)\n",
    "model12.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time History12 = model12.fit(X_train_mat, y_gender, batch_size=256, epochs=25, \\\n",
    "                              validation_split=0.2, callbacks=[lr_decay], verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot the loss and accuracy curves over epochs:\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
    "axs[0].plot(History12.history['loss'], color='b', label='Training loss')\n",
    "axs[0].plot(History12.history['val_loss'], color='r', label='Validation loss')\n",
    "axs[0].set_title(\"Loss curves\")\n",
    "axs[0].legend(loc='best', shadow=True)\n",
    "axs[1].plot(History12.history['acc'], color='b', label='Training accuracy')\n",
    "axs[1].plot(History12.history['val_acc'], color='r', label='Validation accuracy')\n",
    "axs[1].set_title(\"Accuracy curves\")\n",
    "axs[1].legend(loc='best', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "le_age = LabelEncoder()\n",
    "y_age = le_age.fit_transform(train_df.age.values)\n",
    "le_age.classes_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_age[:20]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0])\n",
    "y_age = to_categorical(y_age, num_classes=5)\n",
    "print(f'age shape = {y_age.shape}')\n",
    "y_age"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def model_age(vocab, embed_size, length):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab, output_dim=embed_size, input_length=length))\n",
    "    model.add(LSTM(32, return_sequences = True, dropout=0.25, recurrent_dropout=0.25))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dense(20, activation=\"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(5, activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model2 = model_age(vocab=vocab, embed_size=embed_size, length=length)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define a learning rate decay method:\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', patience=1, verbose=1, \n",
    "                             factor=0.5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time History2 = model2.fit(X_train, y_age, batch_size=256, epochs=3, validation_split=0.2, callbacks=[lr_decay], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn Pipeline Gender"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create pipeline\n",
    "p1 = Pipeline(\n",
    "    [\n",
    "     ('clf_lstm1', KerasClassifier(build_fn=model_gender, epochs=3, batch_size=256, verbose=1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time scores_lstm_gender = cross_val_score(p1, X_t, train_df.gender.values, cv=3, n_jobs=-1, verbose=1)\n",
    "scores_lstm_gender.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores_lstm_gender"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Fit the pipeline for saving its parameters\n",
    "%time p1.fit(X_t, train_df.gender.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn Pipeline age"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create pipeline\n",
    "p2 = Pipeline(\n",
    "    [\n",
    "     ('clf_lstm2', KerasClassifier(build_fn=model_age, epochs=3, batch_size=256, verbose=1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time scores_lstm_age = cross_val_score(p2, X_t, train_df.age.values, cv=3, n_jobs=-1, verbose=1)\n",
    "scores_lstm_age.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores_lstm_age"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Fit the pipeline for saving its parameters\n",
    "%time p2.fit(X_t, train_df.age.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Predict Gender Random Forest_\n",
    "\n",
    "| vectorizer | n_estimators | max_depth | lr | cv_score | current_leader\n",
    "| :--- | --- | --- | --- | --- | --- |\n",
    "| CountVectorizer() | 100 | None | - | 0.66923 | !!!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf_rf1 = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                                min_samples_split=2, min_samples_leaf=1,\n",
    "                                max_features='auto', max_leaf_nodes=None, \n",
    "                                bootstrap=True, oob_score=False, n_jobs=-1, \n",
    "                                random_state=None, verbose=1, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# fit the model and compute the cross-validation score\n",
    "%time scores_rf_gender = cross_val_score(clf_rf1, X_train, y=train_df.gender.values, scoring=None, cv=3, n_jobs=-1, verbose=1)\n",
    "scores_rf_gender.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# alternatively fit the model, compute cross-validation predictions and check the score\n",
    "%time predict_gender = cross_val_predict(clf_rf1, X_train, train_df.gender.values, cv=3, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracy_score(train_df.gender.values, predict_gender)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gender_score = sum(train_df.gender.values==predict_gender)/len(train_df.index)\n",
    "gender_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Make Pipeline for gender prediction_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p1 = Pipeline(\n",
    "    [('count_vect', CountVectorizer()),\n",
    "    ('clf_rf1', clf_rf1)\n",
    "    ])\n",
    "p1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time p1.fit(train_df.domains.values, train_df.gender.values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time gender_predict = p1.predict(train_df.domains.values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracy_score(train_df.gender.values, gender_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Predict Age Random Forest_\n",
    "\n",
    "| vectorizer | n_estimators | max_depth | lr | cv_score | current_leader\n",
    "| :--- | --- | --- | --- | --- | --- |\n",
    "| CountVectorizer() | 100 | None | - | 0.42777 | !!!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf_rf2 = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                                min_samples_split=2, min_samples_leaf=1,\n",
    "                                max_features='auto', max_leaf_nodes=None, \n",
    "                                bootstrap=True, oob_score=False, n_jobs=-1, \n",
    "                                random_state=None, verbose=1, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Compute the cross-validation score\n",
    "%time scores_rf_age = cross_val_score(clf2, X_train, y=train_df.age.values, scoring=None, cv=3, n_jobs=-1, verbose=1)\n",
    "scores_rf_age.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# alternatively compute cross-validation predictions and check the score\n",
    "%time predict_age = cross_val_predict(clf_rf2, X_train, train_df.age.values, cv=3, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "age_score = sum(train_df.age.values==predict_age)/len(train_df.index)\n",
    "age_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "binary_score = sum((train_df.gender.values==predict_gender)&(train_df.age.values==predict_age))/len(train_df.index)\n",
    "binary_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "multiple = age_score * gender_score\n",
    "multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Make Pipeline for Age prediction_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p2 = Pipeline(\n",
    "    [('count_vect', CountVectorizer()),\n",
    "    ('clf_rf2', clf_rf2)\n",
    "    ])\n",
    "p2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time p2.fit(train_df.domains.values, train_df.age.values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time age_predict = p2.predict(train_df.domains.values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracy_score(train_df.age.values, age_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
